Critic_table:
  #Learning rate
  learning_rate: 0.01

  #Discount Factor
  discount_factor: 0.9

  #Eligibility decay
  eli_decay: 0.85

Actor:
  #Learning rate
  learning_rate: 0.7

  #Discount Factor
  discount_factor: 0.9

  #Eligibility decay
  eli_decay: 0.1

  #Epsilon
  epsilon: 0.8

  #Epsilon decay
  epsilon_decay: 0.9956275604353287

Environment:
  #Boardsize
  boardsize: 6

  #Boardtype
  board_type: "Diamond"

  #Open cells
  open_cells: [!!python/tuple [1, 1]]
  #Solvable (1,2),(2,1)
  #Not solvable (1,1),(2,2)

  #Track history
  track_history: True

  #Step reward
  step_reward: 1

  #Final reward
  final_reward: 2

  #Loser penalty
  loser_penalty: -1

Training:
  #Number of episodes
  number_of_episodes: 1000
